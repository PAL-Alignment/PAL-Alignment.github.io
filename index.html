<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A framework to model heterogeneous human preference with multiple reward models">
  <meta name="keywords" content="AI alignment, Heterogeneous Preference Learning, Large Language Models, Reward Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PAL: Pluralistic Alignment Framework for Learning from Heterogeneous Preferences</title>
 
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-N6HD47TZ5G"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-N6HD47TZ5G');
  </script>

  <link rel="icon" href="./static/images/icon.png">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    hr.custom-line {
        border: none;
        border-top: 2px solid black;
        width: 100%;
        margin: 20px auto;
    }
  </style>

</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- title -->
          <h1 class="title is-1 publication-title"><text style="color:#ff3860;">PAL</text>: <text style="color:#ff3860;">P</text><text class="is-size-2">luralistic</text> <text style="color:#ff3860;">AL</text><text class="is-size-2">ignment </text><text class="is-size-2">Framework</text></h1>
          <h3 class="title is-2 publication-title is-size-3">for Learning from Heterogeneous Preferences</h3>
          <br>
          <h5 class="subtitle is-5 publication-awards">ICML TF2M/MFHAIA workshop 2024 (Oral)</h5>
          <!-- authors info -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://chendaiwei-99.github.io/" target="_blank">Daiwei Chen</a>,</span>
            <span class="author-block">
              <a href="https://www.deepneural.network/" target="_blank">Yi Chen</a>,</span>
            <span class="author-block">
              <a href="https://aniketrege.github.io/" target="_blank">Aniket Rege</a>,
            </span>
            <span class="author-block">
              <a href="https://ramyakv.github.io/" target="_blank">Ramya Korakai Vinayak</a>
            </span>
          </div>
          <!-- authors institute -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b>University of Wisconsin-Madison</b></span>
          </div>
          <!-- links -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.08469"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank"
                   rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.08469"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank"
                   rel="noopener noreferrer">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ChenDaiwei-99/PAL-Pluralistic-Alignment-Framework"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank"
                   rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/ramya-ml/pickapic-embeds"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank"
                   rel="noopener noreferrer">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h4 class="subtitle has-text-centered">
        ðŸ”¥<span style="color: #ff3860">[NEW!]</span> <b>PAL Framework</b> has been accepted by 2024 ICML workshop 
        (<a href="https://sites.google.com/view/tf2m" target="_blank">TF2M</a> and <a href="https://sites.google.com/view/mhf-icml2024" target="_blank">MFHAIA</a>)
      </h4>
      <img src="./static/images/PAL-teaser.png" alt="Description of the image">
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- <p>
            Large foundation models pretrained on raw web-scale data are not readily deployable without additional step of extensive alignment to human preferences.
            Such alignment is typically done by collecting large amounts of pairwise comparisons from humans ("Do you prefer output A or B?") and learning a reward model or a policy with the Bradley-Terry-Luce (BTL) model as a proxy for a human's underlying implicit preferences.
            These methods generally suffer from assuming a universal preference shared by all humans, which lacks the flexibility of adapting to plurality of opinions and preferences.
          </p> -->
          <p>
            In this work, we propose PAL, a framework to model human preference complementary to existing pretraining strategies, which incorporates plurality from the ground up.
            We propose using the ideal point model as a lens to view alignment using preference comparisons.
            Together with our novel reformulation and using mixture modeling, our framework captures the plurality of population preferences while simultaneously learning a common preference latent space across different preferences, which can few-shot generalize to new, unseen users.
            Our approach enables us to use the penultimate-layer representation of large foundation models and simple MLP layers to learn reward functions that are on-par with the existing large state-of-the-art reward models, thereby enhancing efficiency of reward modeling significantly. 
            We show that PAL achieves competitive reward model accuracy compared to strong baselines on 1) Language models with Summary dataset ; 2) Image Generative models with Pick-a-Pic dataset ; 3) A new semisynthetic heterogeneous dataset generated using Anthropic Personas. 
          </p>
          <p>
            Finally, our experiments also highlight the shortcoming of current preference datasets that are created using rigid rubrics which wash away heterogeneity, and call for more nuanced data collection approaches.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <hr class="custom-line">
    <div class="columns is-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3 has-text-centered"> <img src="./static/images/icon-yes-no.png" style="width: 5%; height: auto;">&nbsp; What is Ideal Point Model ?</h2>
        <img src="./static/images/ideal-point-model.png" alt="Description of the image">
        <p>
          The ideal point model is a statistical model that is used to analyze the preferences of individuals or groups.
          It is broadly used in political science, sociology, and economics to model the preferences of voters, legislators, or other decision-makers.
          The ideal point model assumes that each individual has an ideal point in a multidimensional space, and that the individual's preference for a particular alternative is a function of <strong style="color: #ff3860;">the distance between the alternative and the individual's ideal point</strong>.
        </p>
      </div>
    </div>
    <hr class="custom-line">
    <div class="columns is-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3 has-text-centered"><img src="./static/images/icon-user-group.png" style="width: 5%; height: auto;">&nbsp; Mixture Modeling on Heterogeneous Human Preference</h2>
        <img src="./static/images/PAL-models.png" alt="Description of the image">
        <p>
          In reality, different people can have different preferences that are not just noisy perturbations of a universal model. That is, people can differ in systematically different ways. However, there are shared aspects across subgroups of people, e.g., owing to demographics, educational, socio-cultural, or other types of similarities. We propose a framework to capture human preferences by considering these differences and similarities 
          by modeling the preferences of individuals with a low-rank model. In particular, we use <strong style="color: #ff3860;">a mixture modeling approach</strong> for capturing diverse preferences where we model each user as a convex combination of K prototypes. 
        </p>
      </div>
    </div>
    <hr class="custom-line">
    <h2 class="title is-3 has-text-centered"><img src="./static/images/icon-dataset.png" style="width: 5%; height: auto;">&nbsp; Heterogeneous Semi-Synthetic Datasets</h2>
    <div class="columns is-centered">
      <div class="column is-half">
        <h5 class="title is-5 has-text-centered"><em>Persona</em> <text style="font-size: small;">dataset</text></h5>
        <div class="is-flex is-align-items-center is-justify-content-center" style="height: 200px;">
          <img src="./static/images/persona.png" alt="Description of the image" style="max-height: 100%; max-width: 100%;">
        </div>
        <p>
          The Anthropic Personas dataset comprises a collection of personalities, each associated with 500 statements that align with the persona and 500 statements that do not.
          <br> <br>
          We utilize this dataset to create a heterogeneous preference dataset by sampling pairs of persona statements and imitating the preference choices of human groups with diverse personality preferences.
        </p>
      </div>
      <div class="column is-half">
        <h5 class="title is-5 has-text-centered"><em>Pick-a-Filter</em> <text style="font-size: small;">dataset</text></h5>
        <div class="is-flex is-align-items-center is-justify-content-center" style="height: 200px;">
          <img src="./static/images/pick-a-filter.png" alt="Description of the image" style="max-height: 100%; max-width: 100%;">
        </div>
        <p>
          The Pick-a-Pic dataset is a large, open dataset for human feedback in text-to-image generation, designed to align pre-trained models with human preferences.
          <br> <br>
          We construct the Pick-a-Filter dataset by adding various color filters to the generated images, thereby explicitly incorporating diverse user preferences into the Pick-a-Pic V1 dataset.
        </p>
      </div>
    </div>
    <hr class="custom-line">
    <div class="columns is-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3 has-text-centered"><img src="./static/images/icon-performance.png" style="width: 5%; height: auto;">&nbsp; Performance</h2>
        <p>
          
        </p>
      </div>
    </div>
  </div>
</section>









<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre>
      <code>@misc{
          chen2024pal,
          title={PAL: Pluralistic Alignment Framework for Learning from Heterogeneous Preferences}, 
          author={Daiwei Chen and Yi Chen and Aniket Rege and Ramya Korlakai Vinayak},
          year={2024},
          eprint={2406.08469},
          archivePrefix={arXiv},
          primaryClass={id='cs.LG' full_name='Machine Learning' is_active=True alt_name=None in_archive='cs' is_general=False description='Papers on all aspects of machine learning research (supervised, unsupervised, reinforcement learning, bandit problems, and so on) including also robustness, explanation, fairness, and methodology. cs.LG is also an appropriate primary category for applications of machine learning methods.'}
        }
      </code>
    </pre>
  </div>
</section>


<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
      <p>
        This work was supported by <b>NSF grants NCS-FO 2219903</b> and <b>NSF CAREER Award CCF 2238876</b>.
      </p>
      <p>
        <b>Usage and License Notices</b>: The data, code and checkpoint is intended and licensed for research use only.
      </p>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="font-size: 12px;">
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
            licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
